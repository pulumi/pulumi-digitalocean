// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.DigitalOcean
{
    /// <summary>
    /// Provides a virtual resource that can be used to change advanced configuration
    /// options for a DigitalOcean managed Kafka database cluster.
    /// 
    /// &gt; **Note** Kafka configurations are only removed from state when destroyed. The remote configuration is not unset.
    /// 
    /// ## Example Usage
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using DigitalOcean = Pulumi.DigitalOcean;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var exampleDatabaseCluster = new DigitalOcean.DatabaseCluster("example", new()
    ///     {
    ///         Name = "example-kafka-cluster",
    ///         Engine = "kafka",
    ///         Version = "3.7",
    ///         Size = DigitalOcean.DatabaseSlug.DB_1VPCU1GB,
    ///         Region = DigitalOcean.Region.NYC3,
    ///         NodeCount = 3,
    ///     });
    /// 
    ///     var example = new DigitalOcean.DatabaseKafkaConfig("example", new()
    ///     {
    ///         ClusterId = exampleDatabaseCluster.Id,
    ///         GroupInitialRebalanceDelayMs = 3000,
    ///         GroupMinSessionTimeoutMs = 6000,
    ///         GroupMaxSessionTimeoutMs = 1800000,
    ///         MessageMaxBytes = 1048588,
    ///         LogCleanerDeleteRetentionMs = 86400000,
    ///         LogCleanerMinCompactionLagMs = "0",
    ///         LogFlushIntervalMs = "9223372036854775807",
    ///         LogIndexIntervalBytes = 4096,
    ///         LogMessageDownconversionEnable = true,
    ///         LogMessageTimestampDifferenceMaxMs = "9223372036854775807",
    ///         LogPreallocate = false,
    ///         LogRetentionBytes = "-1",
    ///         LogRetentionHours = 168,
    ///         LogRetentionMs = "604800000",
    ///         LogRollJitterMs = "0",
    ///         LogSegmentDeleteDelayMs = 60000,
    ///         AutoCreateTopicsEnable = true,
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// A Kafka database cluster's configuration can be imported using the `id` the parent cluster, e.g.
    /// 
    /// ```sh
    /// $ pulumi import digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig example 4b62829a-9c42-465b-aaa3-84051048e712
    /// ```
    /// </summary>
    [DigitalOceanResourceType("digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig")]
    public partial class DatabaseKafkaConfig : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Enable auto creation of topics.
        /// </summary>
        [Output("autoCreateTopicsEnable")]
        public Output<bool> AutoCreateTopicsEnable { get; private set; } = null!;

        /// <summary>
        /// The ID of the target Kafka cluster.
        /// </summary>
        [Output("clusterId")]
        public Output<string> ClusterId { get; private set; } = null!;

        /// <summary>
        /// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
        /// </summary>
        [Output("groupInitialRebalanceDelayMs")]
        public Output<int> GroupInitialRebalanceDelayMs { get; private set; } = null!;

        /// <summary>
        /// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        /// </summary>
        [Output("groupMaxSessionTimeoutMs")]
        public Output<int> GroupMaxSessionTimeoutMs { get; private set; } = null!;

        /// <summary>
        /// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        /// </summary>
        [Output("groupMinSessionTimeoutMs")]
        public Output<int> GroupMinSessionTimeoutMs { get; private set; } = null!;

        /// <summary>
        /// How long are delete records retained?
        /// </summary>
        [Output("logCleanerDeleteRetentionMs")]
        public Output<int> LogCleanerDeleteRetentionMs { get; private set; } = null!;

        /// <summary>
        /// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
        /// </summary>
        [Output("logCleanerMinCompactionLagMs")]
        public Output<string> LogCleanerMinCompactionLagMs { get; private set; } = null!;

        /// <summary>
        /// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        /// </summary>
        [Output("logFlushIntervalMs")]
        public Output<string> LogFlushIntervalMs { get; private set; } = null!;

        /// <summary>
        /// The interval with which Kafka adds an entry to the offset index.
        /// </summary>
        [Output("logIndexIntervalBytes")]
        public Output<int> LogIndexIntervalBytes { get; private set; } = null!;

        /// <summary>
        /// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
        /// </summary>
        [Output("logMessageDownconversionEnable")]
        public Output<bool> LogMessageDownconversionEnable { get; private set; } = null!;

        /// <summary>
        /// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
        /// </summary>
        [Output("logMessageTimestampDifferenceMaxMs")]
        public Output<string> LogMessageTimestampDifferenceMaxMs { get; private set; } = null!;

        /// <summary>
        /// Controls whether to preallocate a file when creating a new segment.
        /// </summary>
        [Output("logPreallocate")]
        public Output<bool> LogPreallocate { get; private set; } = null!;

        /// <summary>
        /// The maximum size of the log before deleting messages.
        /// </summary>
        [Output("logRetentionBytes")]
        public Output<string> LogRetentionBytes { get; private set; } = null!;

        /// <summary>
        /// The number of hours to keep a log file before deleting it.
        /// </summary>
        [Output("logRetentionHours")]
        public Output<int> LogRetentionHours { get; private set; } = null!;

        /// <summary>
        /// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
        /// </summary>
        [Output("logRetentionMs")]
        public Output<string> LogRetentionMs { get; private set; } = null!;

        /// <summary>
        /// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        /// </summary>
        [Output("logRollJitterMs")]
        public Output<string> LogRollJitterMs { get; private set; } = null!;

        /// <summary>
        /// The amount of time to wait before deleting a file from the filesystem.
        /// </summary>
        [Output("logSegmentDeleteDelayMs")]
        public Output<int> LogSegmentDeleteDelayMs { get; private set; } = null!;

        /// <summary>
        /// The maximum size of message that the server can receive.
        /// </summary>
        [Output("messageMaxBytes")]
        public Output<int> MessageMaxBytes { get; private set; } = null!;


        /// <summary>
        /// Create a DatabaseKafkaConfig resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public DatabaseKafkaConfig(string name, DatabaseKafkaConfigArgs args, CustomResourceOptions? options = null)
            : base("digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig", name, args ?? new DatabaseKafkaConfigArgs(), MakeResourceOptions(options, ""))
        {
        }

        private DatabaseKafkaConfig(string name, Input<string> id, DatabaseKafkaConfigState? state = null, CustomResourceOptions? options = null)
            : base("digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing DatabaseKafkaConfig resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static DatabaseKafkaConfig Get(string name, Input<string> id, DatabaseKafkaConfigState? state = null, CustomResourceOptions? options = null)
        {
            return new DatabaseKafkaConfig(name, id, state, options);
        }
    }

    public sealed class DatabaseKafkaConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Enable auto creation of topics.
        /// </summary>
        [Input("autoCreateTopicsEnable")]
        public Input<bool>? AutoCreateTopicsEnable { get; set; }

        /// <summary>
        /// The ID of the target Kafka cluster.
        /// </summary>
        [Input("clusterId", required: true)]
        public Input<string> ClusterId { get; set; } = null!;

        /// <summary>
        /// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
        /// </summary>
        [Input("groupInitialRebalanceDelayMs")]
        public Input<int>? GroupInitialRebalanceDelayMs { get; set; }

        /// <summary>
        /// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        /// </summary>
        [Input("groupMaxSessionTimeoutMs")]
        public Input<int>? GroupMaxSessionTimeoutMs { get; set; }

        /// <summary>
        /// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        /// </summary>
        [Input("groupMinSessionTimeoutMs")]
        public Input<int>? GroupMinSessionTimeoutMs { get; set; }

        /// <summary>
        /// How long are delete records retained?
        /// </summary>
        [Input("logCleanerDeleteRetentionMs")]
        public Input<int>? LogCleanerDeleteRetentionMs { get; set; }

        /// <summary>
        /// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
        /// </summary>
        [Input("logCleanerMinCompactionLagMs")]
        public Input<string>? LogCleanerMinCompactionLagMs { get; set; }

        /// <summary>
        /// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        /// </summary>
        [Input("logFlushIntervalMs")]
        public Input<string>? LogFlushIntervalMs { get; set; }

        /// <summary>
        /// The interval with which Kafka adds an entry to the offset index.
        /// </summary>
        [Input("logIndexIntervalBytes")]
        public Input<int>? LogIndexIntervalBytes { get; set; }

        /// <summary>
        /// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
        /// </summary>
        [Input("logMessageDownconversionEnable")]
        public Input<bool>? LogMessageDownconversionEnable { get; set; }

        /// <summary>
        /// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
        /// </summary>
        [Input("logMessageTimestampDifferenceMaxMs")]
        public Input<string>? LogMessageTimestampDifferenceMaxMs { get; set; }

        /// <summary>
        /// Controls whether to preallocate a file when creating a new segment.
        /// </summary>
        [Input("logPreallocate")]
        public Input<bool>? LogPreallocate { get; set; }

        /// <summary>
        /// The maximum size of the log before deleting messages.
        /// </summary>
        [Input("logRetentionBytes")]
        public Input<string>? LogRetentionBytes { get; set; }

        /// <summary>
        /// The number of hours to keep a log file before deleting it.
        /// </summary>
        [Input("logRetentionHours")]
        public Input<int>? LogRetentionHours { get; set; }

        /// <summary>
        /// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
        /// </summary>
        [Input("logRetentionMs")]
        public Input<string>? LogRetentionMs { get; set; }

        /// <summary>
        /// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        /// </summary>
        [Input("logRollJitterMs")]
        public Input<string>? LogRollJitterMs { get; set; }

        /// <summary>
        /// The amount of time to wait before deleting a file from the filesystem.
        /// </summary>
        [Input("logSegmentDeleteDelayMs")]
        public Input<int>? LogSegmentDeleteDelayMs { get; set; }

        /// <summary>
        /// The maximum size of message that the server can receive.
        /// </summary>
        [Input("messageMaxBytes")]
        public Input<int>? MessageMaxBytes { get; set; }

        public DatabaseKafkaConfigArgs()
        {
        }
        public static new DatabaseKafkaConfigArgs Empty => new DatabaseKafkaConfigArgs();
    }

    public sealed class DatabaseKafkaConfigState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Enable auto creation of topics.
        /// </summary>
        [Input("autoCreateTopicsEnable")]
        public Input<bool>? AutoCreateTopicsEnable { get; set; }

        /// <summary>
        /// The ID of the target Kafka cluster.
        /// </summary>
        [Input("clusterId")]
        public Input<string>? ClusterId { get; set; }

        /// <summary>
        /// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
        /// </summary>
        [Input("groupInitialRebalanceDelayMs")]
        public Input<int>? GroupInitialRebalanceDelayMs { get; set; }

        /// <summary>
        /// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        /// </summary>
        [Input("groupMaxSessionTimeoutMs")]
        public Input<int>? GroupMaxSessionTimeoutMs { get; set; }

        /// <summary>
        /// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
        /// </summary>
        [Input("groupMinSessionTimeoutMs")]
        public Input<int>? GroupMinSessionTimeoutMs { get; set; }

        /// <summary>
        /// How long are delete records retained?
        /// </summary>
        [Input("logCleanerDeleteRetentionMs")]
        public Input<int>? LogCleanerDeleteRetentionMs { get; set; }

        /// <summary>
        /// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
        /// </summary>
        [Input("logCleanerMinCompactionLagMs")]
        public Input<string>? LogCleanerMinCompactionLagMs { get; set; }

        /// <summary>
        /// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        /// </summary>
        [Input("logFlushIntervalMs")]
        public Input<string>? LogFlushIntervalMs { get; set; }

        /// <summary>
        /// The interval with which Kafka adds an entry to the offset index.
        /// </summary>
        [Input("logIndexIntervalBytes")]
        public Input<int>? LogIndexIntervalBytes { get; set; }

        /// <summary>
        /// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
        /// </summary>
        [Input("logMessageDownconversionEnable")]
        public Input<bool>? LogMessageDownconversionEnable { get; set; }

        /// <summary>
        /// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
        /// </summary>
        [Input("logMessageTimestampDifferenceMaxMs")]
        public Input<string>? LogMessageTimestampDifferenceMaxMs { get; set; }

        /// <summary>
        /// Controls whether to preallocate a file when creating a new segment.
        /// </summary>
        [Input("logPreallocate")]
        public Input<bool>? LogPreallocate { get; set; }

        /// <summary>
        /// The maximum size of the log before deleting messages.
        /// </summary>
        [Input("logRetentionBytes")]
        public Input<string>? LogRetentionBytes { get; set; }

        /// <summary>
        /// The number of hours to keep a log file before deleting it.
        /// </summary>
        [Input("logRetentionHours")]
        public Input<int>? LogRetentionHours { get; set; }

        /// <summary>
        /// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
        /// </summary>
        [Input("logRetentionMs")]
        public Input<string>? LogRetentionMs { get; set; }

        /// <summary>
        /// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        /// </summary>
        [Input("logRollJitterMs")]
        public Input<string>? LogRollJitterMs { get; set; }

        /// <summary>
        /// The amount of time to wait before deleting a file from the filesystem.
        /// </summary>
        [Input("logSegmentDeleteDelayMs")]
        public Input<int>? LogSegmentDeleteDelayMs { get; set; }

        /// <summary>
        /// The maximum size of message that the server can receive.
        /// </summary>
        [Input("messageMaxBytes")]
        public Input<int>? MessageMaxBytes { get; set; }

        public DatabaseKafkaConfigState()
        {
        }
        public static new DatabaseKafkaConfigState Empty => new DatabaseKafkaConfigState();
    }
}
