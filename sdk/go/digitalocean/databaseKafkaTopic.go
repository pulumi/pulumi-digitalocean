// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package digitalocean

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-digitalocean/sdk/v4/go/digitalocean/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumix"
)

// Provides a DigitalOcean Kafka topic for Kafka clusters.
//
// ## Example Usage
// ### Create a new Kafka topic
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-digitalocean/sdk/v4/go/digitalocean"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := digitalocean.NewDatabaseCluster(ctx, "kafka-example", &digitalocean.DatabaseClusterArgs{
//				Engine:    pulumi.String("kafka"),
//				Version:   pulumi.String("3.5"),
//				Size:      pulumi.String("db-s-1vcpu-2gb"),
//				Region:    pulumi.String("nyc1"),
//				NodeCount: pulumi.Int(3),
//				Tags: pulumi.StringArray{
//					pulumi.String("production"),
//				},
//			})
//			if err != nil {
//				return err
//			}
//			_, err = digitalocean.NewDatabaseKafkaTopic(ctx, "topic-01", &digitalocean.DatabaseKafkaTopicArgs{
//				ClusterId:         kafka_example.ID(),
//				PartitionCount:    pulumi.Int(3),
//				ReplicationFactor: pulumi.Int(2),
//				Configs: digitalocean.DatabaseKafkaTopicConfigArray{
//					&digitalocean.DatabaseKafkaTopicConfigArgs{
//						CleanupPolicy:                   pulumi.String("compact"),
//						CompressionType:                 pulumi.String("uncompressed"),
//						DeleteRetentionMs:               pulumi.String("14000"),
//						FileDeleteDelayMs:               pulumi.String("170000"),
//						FlushMessages:                   pulumi.String("92233"),
//						FlushMs:                         pulumi.String("92233720368"),
//						IndexIntervalBytes:              pulumi.String("40962"),
//						MaxCompactionLagMs:              pulumi.String("9223372036854775807"),
//						MaxMessageBytes:                 pulumi.String("1048588"),
//						MessageDownConversionEnable:     pulumi.Bool(true),
//						MessageFormatVersion:            pulumi.String("3.0-IV1"),
//						MessageTimestampDifferenceMaxMs: pulumi.String("9223372036854775807"),
//						MessageTimestampType:            pulumi.String("log_append_time"),
//						MinCleanableDirtyRatio:          pulumi.Float64(0.5),
//						MinCompactionLagMs:              pulumi.String("20000"),
//						MinInsyncReplicas:               pulumi.Int(2),
//						Preallocate:                     pulumi.Bool(false),
//						RetentionBytes:                  pulumi.String("-1"),
//						RetentionMs:                     pulumi.String("-1"),
//						SegmentBytes:                    pulumi.String("209715200"),
//						SegmentIndexBytes:               pulumi.String("10485760"),
//						SegmentJitterMs:                 pulumi.String("0"),
//						SegmentMs:                       pulumi.String("604800000"),
//						UncleanLeaderElectionEnable:     pulumi.Bool(true),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// Topics can be imported using the `id` of the source cluster and the `name` of the topic joined with a comma. For example
//
// ```sh
//
//	$ pulumi import digitalocean:index/databaseKafkaTopic:DatabaseKafkaTopic topic-01 245bcfd0-7f31-4ce6-a2bc-475a116cca97,topic-01
//
// ```
type DatabaseKafkaTopic struct {
	pulumi.CustomResourceState

	// The ID of the source database cluster. Note: This must be a Kafka cluster.
	ClusterId pulumi.StringOutput `pulumi:"clusterId"`
	// A set of advanced configuration parameters. Defaults will be set for any of the parameters that are not included.
	// The `config` block is documented below.
	Configs DatabaseKafkaTopicConfigArrayOutput `pulumi:"configs"`
	// The name for the topic.
	Name pulumi.StringOutput `pulumi:"name"`
	// The number of partitions for the topic. Default and minimum set at 3, maximum is 2048.
	PartitionCount pulumi.IntPtrOutput `pulumi:"partitionCount"`
	// The number of nodes that topics are replicated across. Default and minimum set at 2, maximum is the number of nodes in the cluster.
	ReplicationFactor pulumi.IntPtrOutput `pulumi:"replicationFactor"`
	// The current status of the topic. Possible values are 'active', 'configuring', and 'deleting'.
	State pulumi.StringOutput `pulumi:"state"`
}

// NewDatabaseKafkaTopic registers a new resource with the given unique name, arguments, and options.
func NewDatabaseKafkaTopic(ctx *pulumi.Context,
	name string, args *DatabaseKafkaTopicArgs, opts ...pulumi.ResourceOption) (*DatabaseKafkaTopic, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.ClusterId == nil {
		return nil, errors.New("invalid value for required argument 'ClusterId'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource DatabaseKafkaTopic
	err := ctx.RegisterResource("digitalocean:index/databaseKafkaTopic:DatabaseKafkaTopic", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetDatabaseKafkaTopic gets an existing DatabaseKafkaTopic resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetDatabaseKafkaTopic(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *DatabaseKafkaTopicState, opts ...pulumi.ResourceOption) (*DatabaseKafkaTopic, error) {
	var resource DatabaseKafkaTopic
	err := ctx.ReadResource("digitalocean:index/databaseKafkaTopic:DatabaseKafkaTopic", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering DatabaseKafkaTopic resources.
type databaseKafkaTopicState struct {
	// The ID of the source database cluster. Note: This must be a Kafka cluster.
	ClusterId *string `pulumi:"clusterId"`
	// A set of advanced configuration parameters. Defaults will be set for any of the parameters that are not included.
	// The `config` block is documented below.
	Configs []DatabaseKafkaTopicConfig `pulumi:"configs"`
	// The name for the topic.
	Name *string `pulumi:"name"`
	// The number of partitions for the topic. Default and minimum set at 3, maximum is 2048.
	PartitionCount *int `pulumi:"partitionCount"`
	// The number of nodes that topics are replicated across. Default and minimum set at 2, maximum is the number of nodes in the cluster.
	ReplicationFactor *int `pulumi:"replicationFactor"`
	// The current status of the topic. Possible values are 'active', 'configuring', and 'deleting'.
	State *string `pulumi:"state"`
}

type DatabaseKafkaTopicState struct {
	// The ID of the source database cluster. Note: This must be a Kafka cluster.
	ClusterId pulumi.StringPtrInput
	// A set of advanced configuration parameters. Defaults will be set for any of the parameters that are not included.
	// The `config` block is documented below.
	Configs DatabaseKafkaTopicConfigArrayInput
	// The name for the topic.
	Name pulumi.StringPtrInput
	// The number of partitions for the topic. Default and minimum set at 3, maximum is 2048.
	PartitionCount pulumi.IntPtrInput
	// The number of nodes that topics are replicated across. Default and minimum set at 2, maximum is the number of nodes in the cluster.
	ReplicationFactor pulumi.IntPtrInput
	// The current status of the topic. Possible values are 'active', 'configuring', and 'deleting'.
	State pulumi.StringPtrInput
}

func (DatabaseKafkaTopicState) ElementType() reflect.Type {
	return reflect.TypeOf((*databaseKafkaTopicState)(nil)).Elem()
}

type databaseKafkaTopicArgs struct {
	// The ID of the source database cluster. Note: This must be a Kafka cluster.
	ClusterId string `pulumi:"clusterId"`
	// A set of advanced configuration parameters. Defaults will be set for any of the parameters that are not included.
	// The `config` block is documented below.
	Configs []DatabaseKafkaTopicConfig `pulumi:"configs"`
	// The name for the topic.
	Name *string `pulumi:"name"`
	// The number of partitions for the topic. Default and minimum set at 3, maximum is 2048.
	PartitionCount *int `pulumi:"partitionCount"`
	// The number of nodes that topics are replicated across. Default and minimum set at 2, maximum is the number of nodes in the cluster.
	ReplicationFactor *int `pulumi:"replicationFactor"`
}

// The set of arguments for constructing a DatabaseKafkaTopic resource.
type DatabaseKafkaTopicArgs struct {
	// The ID of the source database cluster. Note: This must be a Kafka cluster.
	ClusterId pulumi.StringInput
	// A set of advanced configuration parameters. Defaults will be set for any of the parameters that are not included.
	// The `config` block is documented below.
	Configs DatabaseKafkaTopicConfigArrayInput
	// The name for the topic.
	Name pulumi.StringPtrInput
	// The number of partitions for the topic. Default and minimum set at 3, maximum is 2048.
	PartitionCount pulumi.IntPtrInput
	// The number of nodes that topics are replicated across. Default and minimum set at 2, maximum is the number of nodes in the cluster.
	ReplicationFactor pulumi.IntPtrInput
}

func (DatabaseKafkaTopicArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*databaseKafkaTopicArgs)(nil)).Elem()
}

type DatabaseKafkaTopicInput interface {
	pulumi.Input

	ToDatabaseKafkaTopicOutput() DatabaseKafkaTopicOutput
	ToDatabaseKafkaTopicOutputWithContext(ctx context.Context) DatabaseKafkaTopicOutput
}

func (*DatabaseKafkaTopic) ElementType() reflect.Type {
	return reflect.TypeOf((**DatabaseKafkaTopic)(nil)).Elem()
}

func (i *DatabaseKafkaTopic) ToDatabaseKafkaTopicOutput() DatabaseKafkaTopicOutput {
	return i.ToDatabaseKafkaTopicOutputWithContext(context.Background())
}

func (i *DatabaseKafkaTopic) ToDatabaseKafkaTopicOutputWithContext(ctx context.Context) DatabaseKafkaTopicOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatabaseKafkaTopicOutput)
}

func (i *DatabaseKafkaTopic) ToOutput(ctx context.Context) pulumix.Output[*DatabaseKafkaTopic] {
	return pulumix.Output[*DatabaseKafkaTopic]{
		OutputState: i.ToDatabaseKafkaTopicOutputWithContext(ctx).OutputState,
	}
}

// DatabaseKafkaTopicArrayInput is an input type that accepts DatabaseKafkaTopicArray and DatabaseKafkaTopicArrayOutput values.
// You can construct a concrete instance of `DatabaseKafkaTopicArrayInput` via:
//
//	DatabaseKafkaTopicArray{ DatabaseKafkaTopicArgs{...} }
type DatabaseKafkaTopicArrayInput interface {
	pulumi.Input

	ToDatabaseKafkaTopicArrayOutput() DatabaseKafkaTopicArrayOutput
	ToDatabaseKafkaTopicArrayOutputWithContext(context.Context) DatabaseKafkaTopicArrayOutput
}

type DatabaseKafkaTopicArray []DatabaseKafkaTopicInput

func (DatabaseKafkaTopicArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*DatabaseKafkaTopic)(nil)).Elem()
}

func (i DatabaseKafkaTopicArray) ToDatabaseKafkaTopicArrayOutput() DatabaseKafkaTopicArrayOutput {
	return i.ToDatabaseKafkaTopicArrayOutputWithContext(context.Background())
}

func (i DatabaseKafkaTopicArray) ToDatabaseKafkaTopicArrayOutputWithContext(ctx context.Context) DatabaseKafkaTopicArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatabaseKafkaTopicArrayOutput)
}

func (i DatabaseKafkaTopicArray) ToOutput(ctx context.Context) pulumix.Output[[]*DatabaseKafkaTopic] {
	return pulumix.Output[[]*DatabaseKafkaTopic]{
		OutputState: i.ToDatabaseKafkaTopicArrayOutputWithContext(ctx).OutputState,
	}
}

// DatabaseKafkaTopicMapInput is an input type that accepts DatabaseKafkaTopicMap and DatabaseKafkaTopicMapOutput values.
// You can construct a concrete instance of `DatabaseKafkaTopicMapInput` via:
//
//	DatabaseKafkaTopicMap{ "key": DatabaseKafkaTopicArgs{...} }
type DatabaseKafkaTopicMapInput interface {
	pulumi.Input

	ToDatabaseKafkaTopicMapOutput() DatabaseKafkaTopicMapOutput
	ToDatabaseKafkaTopicMapOutputWithContext(context.Context) DatabaseKafkaTopicMapOutput
}

type DatabaseKafkaTopicMap map[string]DatabaseKafkaTopicInput

func (DatabaseKafkaTopicMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*DatabaseKafkaTopic)(nil)).Elem()
}

func (i DatabaseKafkaTopicMap) ToDatabaseKafkaTopicMapOutput() DatabaseKafkaTopicMapOutput {
	return i.ToDatabaseKafkaTopicMapOutputWithContext(context.Background())
}

func (i DatabaseKafkaTopicMap) ToDatabaseKafkaTopicMapOutputWithContext(ctx context.Context) DatabaseKafkaTopicMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatabaseKafkaTopicMapOutput)
}

func (i DatabaseKafkaTopicMap) ToOutput(ctx context.Context) pulumix.Output[map[string]*DatabaseKafkaTopic] {
	return pulumix.Output[map[string]*DatabaseKafkaTopic]{
		OutputState: i.ToDatabaseKafkaTopicMapOutputWithContext(ctx).OutputState,
	}
}

type DatabaseKafkaTopicOutput struct{ *pulumi.OutputState }

func (DatabaseKafkaTopicOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DatabaseKafkaTopic)(nil)).Elem()
}

func (o DatabaseKafkaTopicOutput) ToDatabaseKafkaTopicOutput() DatabaseKafkaTopicOutput {
	return o
}

func (o DatabaseKafkaTopicOutput) ToDatabaseKafkaTopicOutputWithContext(ctx context.Context) DatabaseKafkaTopicOutput {
	return o
}

func (o DatabaseKafkaTopicOutput) ToOutput(ctx context.Context) pulumix.Output[*DatabaseKafkaTopic] {
	return pulumix.Output[*DatabaseKafkaTopic]{
		OutputState: o.OutputState,
	}
}

// The ID of the source database cluster. Note: This must be a Kafka cluster.
func (o DatabaseKafkaTopicOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaTopic) pulumi.StringOutput { return v.ClusterId }).(pulumi.StringOutput)
}

// A set of advanced configuration parameters. Defaults will be set for any of the parameters that are not included.
// The `config` block is documented below.
func (o DatabaseKafkaTopicOutput) Configs() DatabaseKafkaTopicConfigArrayOutput {
	return o.ApplyT(func(v *DatabaseKafkaTopic) DatabaseKafkaTopicConfigArrayOutput { return v.Configs }).(DatabaseKafkaTopicConfigArrayOutput)
}

// The name for the topic.
func (o DatabaseKafkaTopicOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaTopic) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The number of partitions for the topic. Default and minimum set at 3, maximum is 2048.
func (o DatabaseKafkaTopicOutput) PartitionCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DatabaseKafkaTopic) pulumi.IntPtrOutput { return v.PartitionCount }).(pulumi.IntPtrOutput)
}

// The number of nodes that topics are replicated across. Default and minimum set at 2, maximum is the number of nodes in the cluster.
func (o DatabaseKafkaTopicOutput) ReplicationFactor() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DatabaseKafkaTopic) pulumi.IntPtrOutput { return v.ReplicationFactor }).(pulumi.IntPtrOutput)
}

// The current status of the topic. Possible values are 'active', 'configuring', and 'deleting'.
func (o DatabaseKafkaTopicOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaTopic) pulumi.StringOutput { return v.State }).(pulumi.StringOutput)
}

type DatabaseKafkaTopicArrayOutput struct{ *pulumi.OutputState }

func (DatabaseKafkaTopicArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*DatabaseKafkaTopic)(nil)).Elem()
}

func (o DatabaseKafkaTopicArrayOutput) ToDatabaseKafkaTopicArrayOutput() DatabaseKafkaTopicArrayOutput {
	return o
}

func (o DatabaseKafkaTopicArrayOutput) ToDatabaseKafkaTopicArrayOutputWithContext(ctx context.Context) DatabaseKafkaTopicArrayOutput {
	return o
}

func (o DatabaseKafkaTopicArrayOutput) ToOutput(ctx context.Context) pulumix.Output[[]*DatabaseKafkaTopic] {
	return pulumix.Output[[]*DatabaseKafkaTopic]{
		OutputState: o.OutputState,
	}
}

func (o DatabaseKafkaTopicArrayOutput) Index(i pulumi.IntInput) DatabaseKafkaTopicOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *DatabaseKafkaTopic {
		return vs[0].([]*DatabaseKafkaTopic)[vs[1].(int)]
	}).(DatabaseKafkaTopicOutput)
}

type DatabaseKafkaTopicMapOutput struct{ *pulumi.OutputState }

func (DatabaseKafkaTopicMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*DatabaseKafkaTopic)(nil)).Elem()
}

func (o DatabaseKafkaTopicMapOutput) ToDatabaseKafkaTopicMapOutput() DatabaseKafkaTopicMapOutput {
	return o
}

func (o DatabaseKafkaTopicMapOutput) ToDatabaseKafkaTopicMapOutputWithContext(ctx context.Context) DatabaseKafkaTopicMapOutput {
	return o
}

func (o DatabaseKafkaTopicMapOutput) ToOutput(ctx context.Context) pulumix.Output[map[string]*DatabaseKafkaTopic] {
	return pulumix.Output[map[string]*DatabaseKafkaTopic]{
		OutputState: o.OutputState,
	}
}

func (o DatabaseKafkaTopicMapOutput) MapIndex(k pulumi.StringInput) DatabaseKafkaTopicOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *DatabaseKafkaTopic {
		return vs[0].(map[string]*DatabaseKafkaTopic)[vs[1].(string)]
	}).(DatabaseKafkaTopicOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*DatabaseKafkaTopicInput)(nil)).Elem(), &DatabaseKafkaTopic{})
	pulumi.RegisterInputType(reflect.TypeOf((*DatabaseKafkaTopicArrayInput)(nil)).Elem(), DatabaseKafkaTopicArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*DatabaseKafkaTopicMapInput)(nil)).Elem(), DatabaseKafkaTopicMap{})
	pulumi.RegisterOutputType(DatabaseKafkaTopicOutput{})
	pulumi.RegisterOutputType(DatabaseKafkaTopicArrayOutput{})
	pulumi.RegisterOutputType(DatabaseKafkaTopicMapOutput{})
}
