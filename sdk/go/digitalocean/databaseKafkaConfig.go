// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package digitalocean

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-digitalocean/sdk/v4/go/digitalocean/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Provides a virtual resource that can be used to change advanced configuration
// options for a DigitalOcean managed Kafka database cluster.
//
// > **Note** Kafka configurations are only removed from state when destroyed. The remote configuration is not unset.
//
// ## Example Usage
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-digitalocean/sdk/v4/go/digitalocean"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			exampleDatabaseCluster, err := digitalocean.NewDatabaseCluster(ctx, "example", &digitalocean.DatabaseClusterArgs{
//				Name:      pulumi.String("example-kafka-cluster"),
//				Engine:    pulumi.String("kafka"),
//				Version:   pulumi.String("3.7"),
//				Size:      pulumi.String(digitalocean.DatabaseSlug_DB_1VPCU1GB),
//				Region:    pulumi.String(digitalocean.RegionNYC3),
//				NodeCount: pulumi.Int(3),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = digitalocean.NewDatabaseKafkaConfig(ctx, "example", &digitalocean.DatabaseKafkaConfigArgs{
//				ClusterId:                          exampleDatabaseCluster.ID(),
//				GroupInitialRebalanceDelayMs:       pulumi.Int(3000),
//				GroupMinSessionTimeoutMs:           pulumi.Int(6000),
//				GroupMaxSessionTimeoutMs:           pulumi.Int(1800000),
//				MessageMaxBytes:                    pulumi.Int(1048588),
//				LogCleanerDeleteRetentionMs:        pulumi.Int(86400000),
//				LogCleanerMinCompactionLagMs:       pulumi.String("0"),
//				LogFlushIntervalMs:                 pulumi.String("9223372036854775807"),
//				LogIndexIntervalBytes:              pulumi.Int(4096),
//				LogMessageDownconversionEnable:     pulumi.Bool(true),
//				LogMessageTimestampDifferenceMaxMs: pulumi.String("9223372036854775807"),
//				LogPreallocate:                     pulumi.Bool(false),
//				LogRetentionBytes:                  pulumi.String("-1"),
//				LogRetentionHours:                  pulumi.Int(168),
//				LogRetentionMs:                     pulumi.String("604800000"),
//				LogRollJitterMs:                    pulumi.String("0"),
//				LogSegmentDeleteDelayMs:            pulumi.Int(60000),
//				AutoCreateTopicsEnable:             pulumi.Bool(true),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// A Kafka database cluster's configuration can be imported using the `id` the parent cluster, e.g.
//
// ```sh
// $ pulumi import digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig example 4b62829a-9c42-465b-aaa3-84051048e712
// ```
type DatabaseKafkaConfig struct {
	pulumi.CustomResourceState

	// Enable auto creation of topics.
	AutoCreateTopicsEnable pulumi.BoolOutput `pulumi:"autoCreateTopicsEnable"`
	// The ID of the target Kafka cluster.
	ClusterId pulumi.StringOutput `pulumi:"clusterId"`
	// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
	GroupInitialRebalanceDelayMs pulumi.IntOutput `pulumi:"groupInitialRebalanceDelayMs"`
	// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMaxSessionTimeoutMs pulumi.IntOutput `pulumi:"groupMaxSessionTimeoutMs"`
	// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMinSessionTimeoutMs pulumi.IntOutput `pulumi:"groupMinSessionTimeoutMs"`
	// How long are delete records retained?
	LogCleanerDeleteRetentionMs pulumi.IntOutput `pulumi:"logCleanerDeleteRetentionMs"`
	// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
	LogCleanerMinCompactionLagMs pulumi.StringOutput `pulumi:"logCleanerMinCompactionLagMs"`
	// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
	LogFlushIntervalMs pulumi.StringOutput `pulumi:"logFlushIntervalMs"`
	// The interval with which Kafka adds an entry to the offset index.
	LogIndexIntervalBytes pulumi.IntOutput `pulumi:"logIndexIntervalBytes"`
	// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
	LogMessageDownconversionEnable pulumi.BoolOutput `pulumi:"logMessageDownconversionEnable"`
	// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
	LogMessageTimestampDifferenceMaxMs pulumi.StringOutput `pulumi:"logMessageTimestampDifferenceMaxMs"`
	// Controls whether to preallocate a file when creating a new segment.
	LogPreallocate pulumi.BoolOutput `pulumi:"logPreallocate"`
	// The maximum size of the log before deleting messages.
	LogRetentionBytes pulumi.StringOutput `pulumi:"logRetentionBytes"`
	// The number of hours to keep a log file before deleting it.
	LogRetentionHours pulumi.IntOutput `pulumi:"logRetentionHours"`
	// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
	LogRetentionMs pulumi.StringOutput `pulumi:"logRetentionMs"`
	// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
	LogRollJitterMs pulumi.StringOutput `pulumi:"logRollJitterMs"`
	// The amount of time to wait before deleting a file from the filesystem.
	LogSegmentDeleteDelayMs pulumi.IntOutput `pulumi:"logSegmentDeleteDelayMs"`
	// The maximum size of message that the server can receive.
	MessageMaxBytes pulumi.IntOutput `pulumi:"messageMaxBytes"`
}

// NewDatabaseKafkaConfig registers a new resource with the given unique name, arguments, and options.
func NewDatabaseKafkaConfig(ctx *pulumi.Context,
	name string, args *DatabaseKafkaConfigArgs, opts ...pulumi.ResourceOption) (*DatabaseKafkaConfig, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.ClusterId == nil {
		return nil, errors.New("invalid value for required argument 'ClusterId'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource DatabaseKafkaConfig
	err := ctx.RegisterResource("digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetDatabaseKafkaConfig gets an existing DatabaseKafkaConfig resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetDatabaseKafkaConfig(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *DatabaseKafkaConfigState, opts ...pulumi.ResourceOption) (*DatabaseKafkaConfig, error) {
	var resource DatabaseKafkaConfig
	err := ctx.ReadResource("digitalocean:index/databaseKafkaConfig:DatabaseKafkaConfig", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering DatabaseKafkaConfig resources.
type databaseKafkaConfigState struct {
	// Enable auto creation of topics.
	AutoCreateTopicsEnable *bool `pulumi:"autoCreateTopicsEnable"`
	// The ID of the target Kafka cluster.
	ClusterId *string `pulumi:"clusterId"`
	// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
	GroupInitialRebalanceDelayMs *int `pulumi:"groupInitialRebalanceDelayMs"`
	// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMaxSessionTimeoutMs *int `pulumi:"groupMaxSessionTimeoutMs"`
	// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMinSessionTimeoutMs *int `pulumi:"groupMinSessionTimeoutMs"`
	// How long are delete records retained?
	LogCleanerDeleteRetentionMs *int `pulumi:"logCleanerDeleteRetentionMs"`
	// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
	LogCleanerMinCompactionLagMs *string `pulumi:"logCleanerMinCompactionLagMs"`
	// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
	LogFlushIntervalMs *string `pulumi:"logFlushIntervalMs"`
	// The interval with which Kafka adds an entry to the offset index.
	LogIndexIntervalBytes *int `pulumi:"logIndexIntervalBytes"`
	// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
	LogMessageDownconversionEnable *bool `pulumi:"logMessageDownconversionEnable"`
	// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
	LogMessageTimestampDifferenceMaxMs *string `pulumi:"logMessageTimestampDifferenceMaxMs"`
	// Controls whether to preallocate a file when creating a new segment.
	LogPreallocate *bool `pulumi:"logPreallocate"`
	// The maximum size of the log before deleting messages.
	LogRetentionBytes *string `pulumi:"logRetentionBytes"`
	// The number of hours to keep a log file before deleting it.
	LogRetentionHours *int `pulumi:"logRetentionHours"`
	// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
	LogRetentionMs *string `pulumi:"logRetentionMs"`
	// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
	LogRollJitterMs *string `pulumi:"logRollJitterMs"`
	// The amount of time to wait before deleting a file from the filesystem.
	LogSegmentDeleteDelayMs *int `pulumi:"logSegmentDeleteDelayMs"`
	// The maximum size of message that the server can receive.
	MessageMaxBytes *int `pulumi:"messageMaxBytes"`
}

type DatabaseKafkaConfigState struct {
	// Enable auto creation of topics.
	AutoCreateTopicsEnable pulumi.BoolPtrInput
	// The ID of the target Kafka cluster.
	ClusterId pulumi.StringPtrInput
	// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
	GroupInitialRebalanceDelayMs pulumi.IntPtrInput
	// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMaxSessionTimeoutMs pulumi.IntPtrInput
	// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMinSessionTimeoutMs pulumi.IntPtrInput
	// How long are delete records retained?
	LogCleanerDeleteRetentionMs pulumi.IntPtrInput
	// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
	LogCleanerMinCompactionLagMs pulumi.StringPtrInput
	// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
	LogFlushIntervalMs pulumi.StringPtrInput
	// The interval with which Kafka adds an entry to the offset index.
	LogIndexIntervalBytes pulumi.IntPtrInput
	// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
	LogMessageDownconversionEnable pulumi.BoolPtrInput
	// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
	LogMessageTimestampDifferenceMaxMs pulumi.StringPtrInput
	// Controls whether to preallocate a file when creating a new segment.
	LogPreallocate pulumi.BoolPtrInput
	// The maximum size of the log before deleting messages.
	LogRetentionBytes pulumi.StringPtrInput
	// The number of hours to keep a log file before deleting it.
	LogRetentionHours pulumi.IntPtrInput
	// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
	LogRetentionMs pulumi.StringPtrInput
	// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
	LogRollJitterMs pulumi.StringPtrInput
	// The amount of time to wait before deleting a file from the filesystem.
	LogSegmentDeleteDelayMs pulumi.IntPtrInput
	// The maximum size of message that the server can receive.
	MessageMaxBytes pulumi.IntPtrInput
}

func (DatabaseKafkaConfigState) ElementType() reflect.Type {
	return reflect.TypeOf((*databaseKafkaConfigState)(nil)).Elem()
}

type databaseKafkaConfigArgs struct {
	// Enable auto creation of topics.
	AutoCreateTopicsEnable *bool `pulumi:"autoCreateTopicsEnable"`
	// The ID of the target Kafka cluster.
	ClusterId string `pulumi:"clusterId"`
	// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
	GroupInitialRebalanceDelayMs *int `pulumi:"groupInitialRebalanceDelayMs"`
	// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMaxSessionTimeoutMs *int `pulumi:"groupMaxSessionTimeoutMs"`
	// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMinSessionTimeoutMs *int `pulumi:"groupMinSessionTimeoutMs"`
	// How long are delete records retained?
	LogCleanerDeleteRetentionMs *int `pulumi:"logCleanerDeleteRetentionMs"`
	// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
	LogCleanerMinCompactionLagMs *string `pulumi:"logCleanerMinCompactionLagMs"`
	// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
	LogFlushIntervalMs *string `pulumi:"logFlushIntervalMs"`
	// The interval with which Kafka adds an entry to the offset index.
	LogIndexIntervalBytes *int `pulumi:"logIndexIntervalBytes"`
	// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
	LogMessageDownconversionEnable *bool `pulumi:"logMessageDownconversionEnable"`
	// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
	LogMessageTimestampDifferenceMaxMs *string `pulumi:"logMessageTimestampDifferenceMaxMs"`
	// Controls whether to preallocate a file when creating a new segment.
	LogPreallocate *bool `pulumi:"logPreallocate"`
	// The maximum size of the log before deleting messages.
	LogRetentionBytes *string `pulumi:"logRetentionBytes"`
	// The number of hours to keep a log file before deleting it.
	LogRetentionHours *int `pulumi:"logRetentionHours"`
	// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
	LogRetentionMs *string `pulumi:"logRetentionMs"`
	// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
	LogRollJitterMs *string `pulumi:"logRollJitterMs"`
	// The amount of time to wait before deleting a file from the filesystem.
	LogSegmentDeleteDelayMs *int `pulumi:"logSegmentDeleteDelayMs"`
	// The maximum size of message that the server can receive.
	MessageMaxBytes *int `pulumi:"messageMaxBytes"`
}

// The set of arguments for constructing a DatabaseKafkaConfig resource.
type DatabaseKafkaConfigArgs struct {
	// Enable auto creation of topics.
	AutoCreateTopicsEnable pulumi.BoolPtrInput
	// The ID of the target Kafka cluster.
	ClusterId pulumi.StringInput
	// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
	GroupInitialRebalanceDelayMs pulumi.IntPtrInput
	// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMaxSessionTimeoutMs pulumi.IntPtrInput
	// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
	GroupMinSessionTimeoutMs pulumi.IntPtrInput
	// How long are delete records retained?
	LogCleanerDeleteRetentionMs pulumi.IntPtrInput
	// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
	LogCleanerMinCompactionLagMs pulumi.StringPtrInput
	// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
	LogFlushIntervalMs pulumi.StringPtrInput
	// The interval with which Kafka adds an entry to the offset index.
	LogIndexIntervalBytes pulumi.IntPtrInput
	// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
	LogMessageDownconversionEnable pulumi.BoolPtrInput
	// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
	LogMessageTimestampDifferenceMaxMs pulumi.StringPtrInput
	// Controls whether to preallocate a file when creating a new segment.
	LogPreallocate pulumi.BoolPtrInput
	// The maximum size of the log before deleting messages.
	LogRetentionBytes pulumi.StringPtrInput
	// The number of hours to keep a log file before deleting it.
	LogRetentionHours pulumi.IntPtrInput
	// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
	LogRetentionMs pulumi.StringPtrInput
	// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
	LogRollJitterMs pulumi.StringPtrInput
	// The amount of time to wait before deleting a file from the filesystem.
	LogSegmentDeleteDelayMs pulumi.IntPtrInput
	// The maximum size of message that the server can receive.
	MessageMaxBytes pulumi.IntPtrInput
}

func (DatabaseKafkaConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*databaseKafkaConfigArgs)(nil)).Elem()
}

type DatabaseKafkaConfigInput interface {
	pulumi.Input

	ToDatabaseKafkaConfigOutput() DatabaseKafkaConfigOutput
	ToDatabaseKafkaConfigOutputWithContext(ctx context.Context) DatabaseKafkaConfigOutput
}

func (*DatabaseKafkaConfig) ElementType() reflect.Type {
	return reflect.TypeOf((**DatabaseKafkaConfig)(nil)).Elem()
}

func (i *DatabaseKafkaConfig) ToDatabaseKafkaConfigOutput() DatabaseKafkaConfigOutput {
	return i.ToDatabaseKafkaConfigOutputWithContext(context.Background())
}

func (i *DatabaseKafkaConfig) ToDatabaseKafkaConfigOutputWithContext(ctx context.Context) DatabaseKafkaConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatabaseKafkaConfigOutput)
}

// DatabaseKafkaConfigArrayInput is an input type that accepts DatabaseKafkaConfigArray and DatabaseKafkaConfigArrayOutput values.
// You can construct a concrete instance of `DatabaseKafkaConfigArrayInput` via:
//
//	DatabaseKafkaConfigArray{ DatabaseKafkaConfigArgs{...} }
type DatabaseKafkaConfigArrayInput interface {
	pulumi.Input

	ToDatabaseKafkaConfigArrayOutput() DatabaseKafkaConfigArrayOutput
	ToDatabaseKafkaConfigArrayOutputWithContext(context.Context) DatabaseKafkaConfigArrayOutput
}

type DatabaseKafkaConfigArray []DatabaseKafkaConfigInput

func (DatabaseKafkaConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*DatabaseKafkaConfig)(nil)).Elem()
}

func (i DatabaseKafkaConfigArray) ToDatabaseKafkaConfigArrayOutput() DatabaseKafkaConfigArrayOutput {
	return i.ToDatabaseKafkaConfigArrayOutputWithContext(context.Background())
}

func (i DatabaseKafkaConfigArray) ToDatabaseKafkaConfigArrayOutputWithContext(ctx context.Context) DatabaseKafkaConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatabaseKafkaConfigArrayOutput)
}

// DatabaseKafkaConfigMapInput is an input type that accepts DatabaseKafkaConfigMap and DatabaseKafkaConfigMapOutput values.
// You can construct a concrete instance of `DatabaseKafkaConfigMapInput` via:
//
//	DatabaseKafkaConfigMap{ "key": DatabaseKafkaConfigArgs{...} }
type DatabaseKafkaConfigMapInput interface {
	pulumi.Input

	ToDatabaseKafkaConfigMapOutput() DatabaseKafkaConfigMapOutput
	ToDatabaseKafkaConfigMapOutputWithContext(context.Context) DatabaseKafkaConfigMapOutput
}

type DatabaseKafkaConfigMap map[string]DatabaseKafkaConfigInput

func (DatabaseKafkaConfigMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*DatabaseKafkaConfig)(nil)).Elem()
}

func (i DatabaseKafkaConfigMap) ToDatabaseKafkaConfigMapOutput() DatabaseKafkaConfigMapOutput {
	return i.ToDatabaseKafkaConfigMapOutputWithContext(context.Background())
}

func (i DatabaseKafkaConfigMap) ToDatabaseKafkaConfigMapOutputWithContext(ctx context.Context) DatabaseKafkaConfigMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DatabaseKafkaConfigMapOutput)
}

type DatabaseKafkaConfigOutput struct{ *pulumi.OutputState }

func (DatabaseKafkaConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DatabaseKafkaConfig)(nil)).Elem()
}

func (o DatabaseKafkaConfigOutput) ToDatabaseKafkaConfigOutput() DatabaseKafkaConfigOutput {
	return o
}

func (o DatabaseKafkaConfigOutput) ToDatabaseKafkaConfigOutputWithContext(ctx context.Context) DatabaseKafkaConfigOutput {
	return o
}

// Enable auto creation of topics.
func (o DatabaseKafkaConfigOutput) AutoCreateTopicsEnable() pulumi.BoolOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.BoolOutput { return v.AutoCreateTopicsEnable }).(pulumi.BoolOutput)
}

// The ID of the target Kafka cluster.
func (o DatabaseKafkaConfigOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.ClusterId }).(pulumi.StringOutput)
}

// The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
func (o DatabaseKafkaConfigOutput) GroupInitialRebalanceDelayMs() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.GroupInitialRebalanceDelayMs }).(pulumi.IntOutput)
}

// The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
func (o DatabaseKafkaConfigOutput) GroupMaxSessionTimeoutMs() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.GroupMaxSessionTimeoutMs }).(pulumi.IntOutput)
}

// The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
func (o DatabaseKafkaConfigOutput) GroupMinSessionTimeoutMs() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.GroupMinSessionTimeoutMs }).(pulumi.IntOutput)
}

// How long are delete records retained?
func (o DatabaseKafkaConfigOutput) LogCleanerDeleteRetentionMs() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.LogCleanerDeleteRetentionMs }).(pulumi.IntOutput)
}

// The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
func (o DatabaseKafkaConfigOutput) LogCleanerMinCompactionLagMs() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.LogCleanerMinCompactionLagMs }).(pulumi.StringOutput)
}

// The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
func (o DatabaseKafkaConfigOutput) LogFlushIntervalMs() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.LogFlushIntervalMs }).(pulumi.StringOutput)
}

// The interval with which Kafka adds an entry to the offset index.
func (o DatabaseKafkaConfigOutput) LogIndexIntervalBytes() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.LogIndexIntervalBytes }).(pulumi.IntOutput)
}

// This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
func (o DatabaseKafkaConfigOutput) LogMessageDownconversionEnable() pulumi.BoolOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.BoolOutput { return v.LogMessageDownconversionEnable }).(pulumi.BoolOutput)
}

// The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message.
func (o DatabaseKafkaConfigOutput) LogMessageTimestampDifferenceMaxMs() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.LogMessageTimestampDifferenceMaxMs }).(pulumi.StringOutput)
}

// Controls whether to preallocate a file when creating a new segment.
func (o DatabaseKafkaConfigOutput) LogPreallocate() pulumi.BoolOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.BoolOutput { return v.LogPreallocate }).(pulumi.BoolOutput)
}

// The maximum size of the log before deleting messages.
func (o DatabaseKafkaConfigOutput) LogRetentionBytes() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.LogRetentionBytes }).(pulumi.StringOutput)
}

// The number of hours to keep a log file before deleting it.
func (o DatabaseKafkaConfigOutput) LogRetentionHours() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.LogRetentionHours }).(pulumi.IntOutput)
}

// The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
func (o DatabaseKafkaConfigOutput) LogRetentionMs() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.LogRetentionMs }).(pulumi.StringOutput)
}

// The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
func (o DatabaseKafkaConfigOutput) LogRollJitterMs() pulumi.StringOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.StringOutput { return v.LogRollJitterMs }).(pulumi.StringOutput)
}

// The amount of time to wait before deleting a file from the filesystem.
func (o DatabaseKafkaConfigOutput) LogSegmentDeleteDelayMs() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.LogSegmentDeleteDelayMs }).(pulumi.IntOutput)
}

// The maximum size of message that the server can receive.
func (o DatabaseKafkaConfigOutput) MessageMaxBytes() pulumi.IntOutput {
	return o.ApplyT(func(v *DatabaseKafkaConfig) pulumi.IntOutput { return v.MessageMaxBytes }).(pulumi.IntOutput)
}

type DatabaseKafkaConfigArrayOutput struct{ *pulumi.OutputState }

func (DatabaseKafkaConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*DatabaseKafkaConfig)(nil)).Elem()
}

func (o DatabaseKafkaConfigArrayOutput) ToDatabaseKafkaConfigArrayOutput() DatabaseKafkaConfigArrayOutput {
	return o
}

func (o DatabaseKafkaConfigArrayOutput) ToDatabaseKafkaConfigArrayOutputWithContext(ctx context.Context) DatabaseKafkaConfigArrayOutput {
	return o
}

func (o DatabaseKafkaConfigArrayOutput) Index(i pulumi.IntInput) DatabaseKafkaConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *DatabaseKafkaConfig {
		return vs[0].([]*DatabaseKafkaConfig)[vs[1].(int)]
	}).(DatabaseKafkaConfigOutput)
}

type DatabaseKafkaConfigMapOutput struct{ *pulumi.OutputState }

func (DatabaseKafkaConfigMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*DatabaseKafkaConfig)(nil)).Elem()
}

func (o DatabaseKafkaConfigMapOutput) ToDatabaseKafkaConfigMapOutput() DatabaseKafkaConfigMapOutput {
	return o
}

func (o DatabaseKafkaConfigMapOutput) ToDatabaseKafkaConfigMapOutputWithContext(ctx context.Context) DatabaseKafkaConfigMapOutput {
	return o
}

func (o DatabaseKafkaConfigMapOutput) MapIndex(k pulumi.StringInput) DatabaseKafkaConfigOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *DatabaseKafkaConfig {
		return vs[0].(map[string]*DatabaseKafkaConfig)[vs[1].(string)]
	}).(DatabaseKafkaConfigOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*DatabaseKafkaConfigInput)(nil)).Elem(), &DatabaseKafkaConfig{})
	pulumi.RegisterInputType(reflect.TypeOf((*DatabaseKafkaConfigArrayInput)(nil)).Elem(), DatabaseKafkaConfigArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*DatabaseKafkaConfigMapInput)(nil)).Elem(), DatabaseKafkaConfigMap{})
	pulumi.RegisterOutputType(DatabaseKafkaConfigOutput{})
	pulumi.RegisterOutputType(DatabaseKafkaConfigArrayOutput{})
	pulumi.RegisterOutputType(DatabaseKafkaConfigMapOutput{})
}
